{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "887c3a20",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook cleanes the dataset of models' responses to the reading_comprehension question pool:\n",
    "- Merges datasets responses generated from different runs of the script\n",
    "- Pivots horizontally the dataset\n",
    "- Divides the <think> part from the actual response in deepseek-r1's answers\n",
    "- Divides the different sections of the response in ##Reasoning and ##Solution, extracting them with tailored regexes\n",
    "- Assigns a score 0-1 based on whether the structure response instructions were followed or not\n",
    "- Adds colums from original datasets for additional information, for proper evaluation\n",
    "- Assign a score 0-1 based on whether the models aswered correctly or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"llm-justification-evaluation\", \"Data_cleaning_cosine_calculation_semantic_and_analysis\")\n",
    "os.chdir(desktop_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e847274",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_pippo= pd.read_csv('Models_answers/reading_comprehension_answers.csv')\n",
    "read_luca= pd.read_csv('Models_answers/reading_comprehension_answers_luca.csv')\n",
    "read_pippo = read_pippo[~read_pippo['model'].isin(['deepseek-r1:1.5b'])]\n",
    "read_pippo = read_pippo.drop_duplicates(subset=['QuestionID', 'model'], keep='last')\n",
    "read_=pd.concat([read_pippo, read_luca]).reset_index(drop=True)\n",
    "read_ = read_[~read_['response'].str.contains('Error: 1 ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21345bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_response = read_.pivot(index='QuestionID', columns='model', values='response').reset_index()\n",
    "\n",
    "import re\n",
    "def split_think(text):\n",
    "    if isinstance(text, str):\n",
    "        match = re.search(r\"<think>(.*?)</think>\", text, re.DOTALL)\n",
    "        if match:\n",
    "            think_part = match.group(1).strip()\n",
    "            response_part = text.replace(match.group(0), \"\").strip()\n",
    "            return pd.Series([think_part, response_part])\n",
    "    return pd.Series([\"\", text])\n",
    "\n",
    "read_response[['deepseek-r1:1.5b_think', 'deepseek-r1:1.5b']] = read_response['deepseek-r1:1.5b'].apply(split_think)\n",
    "read_response[['deepseek-r1:14b_think', 'deepseek-r1:14b']] = read_response['deepseek-r1:14b'].apply(split_think)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff944816",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_time= read_.pivot(index='QuestionID', columns='model', values='time_taken_seconds').reset_index()\n",
    "read_time.columns = [f\"{col}_time\" for col in read_time.columns]\n",
    "read_analysis = pd.concat([read_response, read_time], axis=1).reset_index()\n",
    "read_analysis = read_analysis.drop(columns=['QuestionID_time', 'index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7b0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Additional_information_datasets/reading_comprehension_pool.csv')\n",
    "data_to_merge=data[['QuestionID','Answer', 'Solution', 'PassageText', 'QuestionText']]\n",
    "read_analysis = read_analysis.merge(data_to_merge, on='QuestionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf5772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_argument_answer(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\", \"\", 1  \n",
    "\n",
    "    text = text.strip()\n",
    "    arg_marker = \"## Reasoning\"\n",
    "    ans_marker = \"## Solution\"\n",
    "\n",
    "    arg_index = text.find(arg_marker)\n",
    "    ans_index = text.find(ans_marker)\n",
    "\n",
    "    if arg_index != -1 and ans_index != -1 and arg_index < ans_index:\n",
    "        evaluation = text[arg_index + len(arg_marker):ans_index].strip()\n",
    "        solution = text[ans_index + len(ans_marker):].strip()\n",
    "        return evaluation, solution, 0  \n",
    "\n",
    "    return text.strip(), text.strip(), 1\n",
    "\n",
    "\n",
    "model_names = [\"deepseek-r1:1.5b\", \"deepseek-r1:14b\", \"qwen2.5:14b\", \"qwen2.5:1.5b\"]\n",
    "\n",
    "for model_name in model_names:\n",
    "    source_col = model_name\n",
    "    eval_col = f\"{model_name}_evaluation\"\n",
    "    sol_col = f\"{model_name}_solution\"\n",
    "    score_col = f\"{model_name}_structure_score\"\n",
    "\n",
    "    results = read_analysis[source_col].apply(split_argument_answer)\n",
    "    read_analysis[[eval_col, sol_col, score_col]] = pd.DataFrame(results.tolist(), index=read_analysis.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60df6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_analysis = read_analysis.drop(columns=['deepseek-r1:1.5b_think', 'deepseek-r1:14b_think'])\n",
    "read_analysis = read_analysis[read_analysis['Solution'] != 'Solution not found.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "497adff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def clean_solution(text):\n",
    "    if not isinstance(text, str):\n",
    "        return np.nan\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"\"\"(?ix) \n",
    "        (?:\\\\boxed\\{\\\\text\\{([A-E])\\}\\})\n",
    "        |(?:\\\\text\\{([A-E])\\})\n",
    "        |(?:\\*\\*\\s*([A-E])\\s*\\*\\*) \n",
    "        |(?:\\(\\s*([A-E])\\s*\\))\n",
    "        |(?:[#>*\\-]+\\s*([A-E]))\n",
    "        |(?:(?:answer|solution|final\\s+answer|correct\\s+answer\\s+is)[\\s:\\n\\*]*([A-E]))\n",
    "        |(?:^([A-E])$)\n",
    "        \"\"\",\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    match = pattern.search(text)\n",
    "    if match:\n",
    "        for group in match.groups():\n",
    "            if group:\n",
    "                return group.upper()\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "model_names = [\"deepseek-r1:1.5b\", \"deepseek-r1:14b\", \"qwen2.5:14b\", \"qwen2.5:1.5b\"]\n",
    "\n",
    "for model_name in model_names:\n",
    "    sol_col = f\"{model_name}_solution\"\n",
    "    read_analysis[sol_col] = read_analysis[sol_col].apply(clean_solution)\n",
    "\n",
    "read_analysis.columns = [col.replace('_evaluation', '_reasoning') if '_evaluation' in col else col for col in read_analysis.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2783a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"deepseek-r1:1.5b\", \"deepseek-r1:14b\", \"qwen2.5:1.5b\", \"qwen2.5:14b\"]\n",
    "for model_name in model_names:\n",
    "    sol_col = f\"{model_name}_solution\"\n",
    "    ans_col = 'Answer'\n",
    "    correct_col = f\"{model_name}_correct\"\n",
    "    \n",
    "    read_analysis[correct_col] = np.where(read_analysis[sol_col] == read_analysis[ans_col], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d8422b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "read_analysis.to_csv('NLP_analysis/reading_comprehension_analysis.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
